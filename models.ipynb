{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a15abe14-6fb3-4adb-8b41-d2d7f767314a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn \n",
    "import pandas as pd \n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87849b93-f0cb-41d3-b0cc-c51d9aa7d6e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiceLoss(torch.nn.Module):\n",
    "    def __init__(self, n_classes, softmax=False,weight=None):\n",
    "        super(DiceLoss, self).__init__()\n",
    "        self.n_classes = n_classes\n",
    "        self.softmax = softmax\n",
    "        self.weight = weight\n",
    "\n",
    "    def _one_hot_encoder(self, input_tensor):\n",
    "        tensor_list = []\n",
    "        for i in range(self.n_classes):\n",
    "            temp_prob = input_tensor == i * torch.ones_like(input_tensor)\n",
    "            tensor_list.append(temp_prob)\n",
    "        output_tensor = torch.cat(tensor_list, dim=1)\n",
    "        return output_tensor.float()\n",
    "\n",
    "    def _dice_loss(self, score, target):\n",
    "        target = target.float()\n",
    "        smooth = 1e-5\n",
    "        intersect = torch.sum(score * target)\n",
    "        y_sum = torch.sum(target * target)\n",
    "        z_sum = torch.sum(score * score)\n",
    "        loss = (2 * intersect + smooth) / (z_sum + y_sum + smooth)\n",
    "        loss = 1 - loss\n",
    "        return loss\n",
    "\n",
    "    def forward(self, inputs, target):\n",
    "        if self.softmax:\n",
    "            inputs = torch.softmax(inputs, dim=1)\n",
    "        if target.dim() < inputs.dim():\n",
    "            target = target.unsqueeze(1)\n",
    "        if target.shape[1] == 1 and target.shape[1] < inputs.shape[1]:\n",
    "            target = self._one_hot_encoder(target)\n",
    "\n",
    "        if self.weight is None:\n",
    "            self.weight = [1] * self.n_classes\n",
    "        assert inputs.size() == target.size(), f'predict & target shape do not match, with inputs={inputs.shape}, target={target.shape})'\n",
    "        class_wise_dice = []\n",
    "        loss = 0.0\n",
    "        for i in range(0, self.n_classes):\n",
    "            dice = self._dice_loss(inputs[:, i], target[:, i])\n",
    "            class_wise_dice.append(1.0 - dice.item())\n",
    "            loss += dice * self.weight[i]\n",
    "        return loss / self.n_classes\n",
    "\n",
    "\n",
    "\n",
    "class CategoricalFocalLoss(nn.Module):\n",
    "    def __init__(self, gamma=2.0, alpha=None, reduction='mean'):\n",
    "        super(CategoricalFocalLoss, self).__init__()\n",
    "        self.gamma = gamma\n",
    "        self.alpha = alpha\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        log_prob = F.log_softmax(input, dim=1)\n",
    "        prob = torch.exp(log_prob)\n",
    "\n",
    "        # Calculate focal loss\n",
    "        focal_loss = -((1 - prob) ** self.gamma) * log_prob * target\n",
    "\n",
    "        # Apply alpha weighting if provided\n",
    "        if self.alpha is not None:\n",
    "            alpha = self.alpha.to(input.device)\n",
    "            focal_loss = alpha * focal_loss\n",
    "\n",
    "        # Apply reduction\n",
    "        if self.reduction == 'mean':\n",
    "            focal_loss = focal_loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            focal_loss = focal_loss.sum()\n",
    "\n",
    "        return focal_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49156156-c0b9-464e-8ea0-e6c032fde24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Conv_layer\n",
    "class conv_block(nn.Module):\n",
    "    def __init__(self, in_c, out_c):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_c, out_c, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(out_c)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(out_c, out_c, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(out_c)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x = self.conv1(inputs)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "# Build Encoder section\n",
    "class encoder_block(nn.Module):\n",
    "    def __init__(self, in_c, out_c):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv = conv_block(in_c, out_c)\n",
    "        self.pool = nn.MaxPool2d((2, 2))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x = self.conv(inputs)\n",
    "        p = self.pool(x)\n",
    "\n",
    "        return x, p\n",
    "\n",
    "\n",
    "# Build Decoder section\n",
    "class decoder_block(nn.Module):\n",
    "    def __init__(self, in_c, out_c):\n",
    "        super().__init__()\n",
    "\n",
    "        self.up = nn.ConvTranspose2d(in_c, out_c, kernel_size=2, stride=2, padding=0)\n",
    "        self.conv = conv_block(out_c+out_c, out_c)\n",
    "\n",
    "    def forward(self, inputs, skip):\n",
    "        x = self.up(inputs)\n",
    "        x = torch.cat([x, skip], axis=1)\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Build Unet architecture\n",
    "class build_unet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # Encoder\n",
    "        self.e1 = encoder_block(3, 64)\n",
    "        self.e2 = encoder_block(64, 128)\n",
    "        self.e3 = encoder_block(128, 256)\n",
    "        self.e4 = encoder_block(256, 512)\n",
    "\n",
    "        # Bottleneck\n",
    "        self.b = conv_block(512, 1024)\n",
    "\n",
    "        # Decoder\n",
    "        self.d1 = decoder_block(1024, 512)\n",
    "        self.d2 = decoder_block(512, 256)\n",
    "        self.d3 = decoder_block(256, 128)\n",
    "        self.d4 = decoder_block(128, 64)\n",
    "\n",
    "        # Classifier\n",
    "        self.outputs = nn.Conv2d(64, 7, kernel_size=1, padding=0)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        # Encoder\n",
    "        s1, p1 = self.e1(inputs)\n",
    "        s2, p2 = self.e2(p1)\n",
    "        s3, p3 = self.e3(p2)\n",
    "        s4, p4 = self.e4(p3)\n",
    "\n",
    "        # Bottleneck\n",
    "        b = self.b(p4)\n",
    "\n",
    "        # Decoder\n",
    "        d1 = self.d1(b, s4)\n",
    "        d2 = self.d2(d1, s3)\n",
    "        d3 = self.d3(d2, s2)\n",
    "        d4 = self.d4(d3, s1)\n",
    "\n",
    "        outputs = self.outputs(d4)\n",
    "\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e502a6d9-bc07-4ad4-b893-880338cdfaf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def validlossf1(model,ds,loss_fn,num_classes):\n",
    "#     f1_list=[]\n",
    "#     loss_list=[]\n",
    "    \n",
    "#     model.eval()\n",
    "#     for img, mask, orig, _ in ds:\n",
    "#         img = img.to(device)\n",
    "#         mask = mask.to(device)\n",
    "#         with torch.no_grad():\n",
    "#             output = model(img.float().unsqueeze(0))\n",
    "#         loss = loss_fn(output,mask.float().unsqueeze(0))\n",
    "#         pred = torch.argmax(output, dim=1).squeeze(0)\n",
    "#         pred = pred.to(\"cpu\")\n",
    "        \n",
    "#         f1_scores = np.zeros(num_classes)\n",
    "        \n",
    "#         for class_label in range(num_classes):  # F1 score and loss for current class\n",
    "#             pred_class = (pred == class_label)\n",
    "#             real_class = (orig == class_label)\n",
    "            \n",
    "#             true_positives = np.sum(np.logical_and(pred_class, real_class).numpy())\n",
    "#             false_positives = np.sum(np.logical_and(pred_class, ~real_class).numpy())\n",
    "#             false_negatives = np.sum(np.logical_and(~pred_class, real_class).numpy())\n",
    "            \n",
    "#             precision = true_positives / (true_positives + false_positives)\n",
    "#             recall = true_positives / (true_positives + false_negatives)\n",
    "            \n",
    "#             f1_scores[class_label] = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "#         f1_list.append(f1_scores)\n",
    "#         loss_list.append(loss.item())\n",
    "      \n",
    "\n",
    "#     average_loss = np.average(loss_list)\n",
    "#     f1df = pd.DataFrame(f1_list)\n",
    "#     f1avg = f1df[f1df != 0].mean()\n",
    "#     average_f1 = np.average(f1avg)\n",
    "\n",
    "#     return average_loss,average_f1,f1avg\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80f95992-015c-4710-8c2a-adff7612cf4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validlossf1(model, ds, loss_fn, num_classes):\n",
    "    f1_list = []\n",
    "    loss_list = []\n",
    "    \n",
    "    model.eval()\n",
    "    for img, mask, orig, _ in ds:\n",
    "        img = img.to(device)\n",
    "        mask = mask.to(device)\n",
    "        with torch.no_grad():\n",
    "            output = model(img.float().unsqueeze(0))\n",
    "        loss = loss_fn(output, mask.float().unsqueeze(0))\n",
    "        pred = torch.argmax(output, dim=1).squeeze(0)\n",
    "        pred = pred.to(\"cpu\")\n",
    "        \n",
    "        f1_scores = np.zeros(num_classes)\n",
    "        \n",
    "        for class_label in range(num_classes):  # F1 score and loss for the current class\n",
    "            pred_class = (pred == class_label)\n",
    "            real_class = (orig == class_label)\n",
    "            \n",
    "            true_positives = np.sum(np.logical_and(pred_class, real_class).numpy())\n",
    "            false_positives = np.sum(np.logical_and(pred_class, ~real_class).numpy())\n",
    "            false_negatives = np.sum(np.logical_and(~pred_class, real_class).numpy())\n",
    "            \n",
    "            precision = true_positives / (true_positives + false_positives)\n",
    "            recall = true_positives / (true_positives + false_negatives)\n",
    "            \n",
    "            f1_scores[class_label] = 2 * (precision * recall) / (precision + recall)\n",
    "        \n",
    "        f1_list.append(np.round(list(f1_scores),5))\n",
    "        loss_list.append(loss.item())\n",
    "      \n",
    "    average_loss = np.average(loss_list)\n",
    "    f1df = pd.DataFrame(f1_list)\n",
    "    f1avg = f1df[f1df != 0].mean()\n",
    "    average_f1 = np.round(np.average(f1avg),5)\n",
    "\n",
    "    return np.round(average_loss,7), np.round(average_f1,5), np.round(f1avg,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6d6df7-40c5-4bc1-96fb-498ca87b76e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validlossf2(model, ds, loss_fn, num_classes):\n",
    "    f1_list = []\n",
    "    loss_list = []\n",
    "    \n",
    "    model.eval()\n",
    "    for img, mask, orig, _ in ds:\n",
    "        img = img.to(device)\n",
    "        mask = mask.to(device)\n",
    "        with torch.no_grad():\n",
    "            output = model(img.float().unsqueeze(0))\n",
    "        loss = loss_fn(output, mask.float().unsqueeze(0))\n",
    "        pred = torch.argmax(output, dim=1).squeeze(0)\n",
    "        pred = pred.to(\"cpu\")\n",
    "        \n",
    "        f1_scores = np.zeros(num_classes)\n",
    "        \n",
    "        for class_label in range(num_classes):  # F1 score and loss for the current class\n",
    "            pred_class = (pred == class_label)\n",
    "            real_class = (orig == class_label)\n",
    "            \n",
    "            true_positives = np.sum(np.logical_and(pred_class, real_class).numpy())\n",
    "            false_positives = np.sum(np.logical_and(pred_class, ~real_class).numpy())\n",
    "            false_negatives = np.sum(np.logical_and(~pred_class, real_class).numpy())\n",
    "            \n",
    "            precision = true_positives / (true_positives + false_positives)\n",
    "            recall = true_positives / (true_positives + false_negatives)\n",
    "            \n",
    "            f1_scores[class_label] = 2 * (precision * recall) / (precision + recall)\n",
    "        \n",
    "        f1_list.append(np.round(list(f1_scores),5))\n",
    "        loss_list.append(loss.item())\n",
    "      \n",
    "    average_loss = np.average(loss_list)\n",
    "    f1df = pd.DataFrame(f1_list)\n",
    "    f1avg = f1df[f1df != 0].mean()\n",
    "    average_f1 = np.round(np.average(f1avg),5)\n",
    "\n",
    "    return np.round(average_loss,7), np.round(average_f1,5), np.round(f1avg,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18e49c6c-062c-4231-bfdb-88ae6ac1b7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "from torch.nn import functional as F\n",
    "\n",
    "\n",
    "__all__ = ['ResNet', 'resnet50', 'resnet101', 'resnet152']\n",
    "\n",
    "\n",
    "model_urls = {\n",
    "    'resnet50': 'https://download.pytorch.org/models/resnet50-19c8e357.pth',\n",
    "    'resnet101': 'https://download.pytorch.org/models/resnet101-5d3b4d8f.pth',\n",
    "    'resnet152': 'https://download.pytorch.org/models/resnet152-b121ed2d.pth',\n",
    "}\n",
    "class _FCNHead(nn.Module):\n",
    "    def __init__(self, in_channels, channels, norm_layer=nn.BatchNorm2d, **kwargs):\n",
    "        super(_FCNHead, self).__init__()\n",
    "        inter_channels = in_channels // 4\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, inter_channels, 3, padding=1, bias=False),\n",
    "            norm_layer(inter_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Conv2d(inter_channels, channels, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "\n",
    "class Conv2d(nn.Conv2d):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride=1,\n",
    "                 padding=0, dilation=1, groups=1, bias=True):\n",
    "        super(Conv2d, self).__init__(in_channels, out_channels, kernel_size, stride,\n",
    "                 padding, dilation, groups, bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # return super(Conv2d, self).forward(x)\n",
    "        weight = self.weight\n",
    "        weight_mean = weight.mean(dim=1, keepdim=True).mean(dim=2,\n",
    "                                  keepdim=True).mean(dim=3, keepdim=True)\n",
    "        weight = weight - weight_mean\n",
    "        std = weight.view(weight.size(0), -1).std(dim=1).view(-1, 1, 1, 1) + 1e-5\n",
    "        weight = weight / std.expand_as(weight)\n",
    "        return F.conv2d(x, weight, self.bias, self.stride,\n",
    "                        self.padding, self.dilation, self.groups)\n",
    "\n",
    "\n",
    "class ASPP(nn.Module):\n",
    "\n",
    "    def __init__(self, C, depth, num_classes, conv=nn.Conv2d, norm=nn.BatchNorm2d, momentum=0.0003, mult=1):\n",
    "        super(ASPP, self).__init__()\n",
    "        self._C = C\n",
    "        self._depth = depth\n",
    "        self._num_classes = num_classes\n",
    "\n",
    "        self.global_pooling = nn.AdaptiveAvgPool2d(1)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.aspp1 = conv(C, depth, kernel_size=1, stride=1, bias=False)\n",
    "        self.aspp2 = conv(C, depth, kernel_size=3, stride=1,\n",
    "                               dilation=int(6*mult), padding=int(6*mult),\n",
    "                               bias=False)\n",
    "        self.aspp3 = conv(C, depth, kernel_size=3, stride=1,\n",
    "                               dilation=int(12*mult), padding=int(12*mult),\n",
    "                               bias=False)\n",
    "        self.aspp4 = conv(C, depth, kernel_size=3, stride=1,\n",
    "                               dilation=int(18*mult), padding=int(18*mult),\n",
    "                               bias=False)\n",
    "        self.aspp5 = conv(C, depth, kernel_size=1, stride=1, bias=False)\n",
    "        self.aspp1_bn = norm(depth, momentum)\n",
    "        self.aspp2_bn = norm(depth, momentum)\n",
    "        self.aspp3_bn = norm(depth, momentum)\n",
    "        self.aspp4_bn = norm(depth, momentum)\n",
    "        self.aspp5_bn = norm(depth, momentum)\n",
    "        self.conv2 = conv(depth * 5, depth, kernel_size=1, stride=1,\n",
    "                               bias=False)\n",
    "        self.bn2 = norm(depth, momentum)\n",
    "        self.conv3 = nn.Conv2d(depth, num_classes, kernel_size=1, stride=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.aspp1(x)\n",
    "        x1 = self.aspp1_bn(x1)\n",
    "        x1 = self.relu(x1)\n",
    "        x2 = self.aspp2(x)\n",
    "        x2 = self.aspp2_bn(x2)\n",
    "        x2 = self.relu(x2)\n",
    "        x3 = self.aspp3(x)\n",
    "        x3 = self.aspp3_bn(x3)\n",
    "        x3 = self.relu(x3)\n",
    "        x4 = self.aspp4(x)\n",
    "        x4 = self.aspp4_bn(x4)\n",
    "        x4 = self.relu(x4)\n",
    "        x5 = self.global_pooling(x)\n",
    "        x5 = self.aspp5(x5)\n",
    "        x5 = self.aspp5_bn(x5)\n",
    "        x5 = self.relu(x5)\n",
    "        x5 = nn.Upsample((x.shape[2], x.shape[3]), mode='bilinear',\n",
    "                         align_corners=True)(x5)\n",
    "        x = torch.cat((x1, x2, x3, x4, x5), 1)\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv3(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    expansion = 4\n",
    "\n",
    "    def __init__(self, inplanes, planes, stride=1, downsample=None, dilation=1, conv=None, norm=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.conv1 = conv(inplanes, planes, kernel_size=1, bias=False)\n",
    "        self.bn1 = norm(planes)\n",
    "        self.conv2 = conv(planes, planes, kernel_size=3, stride=stride,\n",
    "                               dilation=dilation, padding=dilation, bias=False)\n",
    "        self.bn2 = norm(planes)\n",
    "        self.conv3 = conv(planes, planes * self.expansion, kernel_size=1, bias=False)\n",
    "        self.bn3 = norm(planes * self.expansion)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.downsample = downsample\n",
    "        self.stride = stride\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv3(out)\n",
    "        out = self.bn3(out)\n",
    "\n",
    "        if self.downsample is not None:\n",
    "            residual = self.downsample(x)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "\n",
    "    def __init__(self, block, layers, num_classes, num_groups=None, weight_std=False, beta=False):\n",
    "        self.inplanes = 64\n",
    "        self.norm = lambda planes, momentum=0.05: nn.BatchNorm2d(planes, momentum=momentum) if num_groups is None else nn.GroupNorm(num_groups, planes)\n",
    "        self.conv = Conv2d if weight_std else nn.Conv2d\n",
    "\n",
    "        super(ResNet, self).__init__()\n",
    "        if not beta:\n",
    "            self.conv1 = self.conv(3, 64, kernel_size=7, stride=2, padding=3,\n",
    "                                   bias=False)\n",
    "        else:\n",
    "            self.conv1 = nn.Sequential(\n",
    "                self.conv(3, 64, 3, stride=2, padding=1, bias=False),\n",
    "                self.conv(64, 64, 3, stride=1, padding=1, bias=False),\n",
    "                self.conv(64, 64, 3, stride=1, padding=1, bias=False))\n",
    "        self.bn1 = self.norm(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4 = self._make_layer(block, 512, layers[3], stride=1,\n",
    "                                       dilation=2)\n",
    "        self.aspp = ASPP(512 * block.expansion, 256, num_classes, conv=self.conv, norm=self.norm)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, self.conv):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d) or isinstance(m, nn.GroupNorm):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def _make_layer(self, block, planes, blocks, stride=1, dilation=1):\n",
    "        downsample = None\n",
    "        if stride != 1 or dilation != 1 or self.inplanes != planes * block.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                self.conv(self.inplanes, planes * block.expansion,\n",
    "                          kernel_size=1, stride=stride, dilation=max(1, dilation/2), bias=False),\n",
    "                self.norm(planes * block.expansion),\n",
    "            )\n",
    "\n",
    "        layers = []\n",
    "        layers.append(block(self.inplanes, planes, stride, downsample, dilation=max(1, dilation/2), conv=self.conv, norm=self.norm))\n",
    "        self.inplanes = planes * block.expansion\n",
    "        for i in range(1, blocks):\n",
    "            layers.append(block(self.inplanes, planes, dilation=dilation, conv=self.conv, norm=self.norm))\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        size = (x.shape[2], x.shape[3])\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.aspp(x)\n",
    "        x = nn.Upsample(size, mode='bilinear', align_corners=True)(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "def resnet50(pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-50 model.\n",
    "\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(Bottleneck, [3, 4, 6, 3], **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet50']))\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet101(pretrained=False, num_groups=None, weight_std=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-101 model.\n",
    "\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(Bottleneck, [3, 4, 23, 3], num_groups=num_groups, weight_std=weight_std, **kwargs)\n",
    "    if pretrained:\n",
    "        model_dict = model.state_dict()\n",
    "        if num_groups and weight_std:\n",
    "            pretrained_dict = torch.load('data/R-101-GN-WS.pth.tar')\n",
    "            overlap_dict = {k[7:]: v for k, v in pretrained_dict.items() if k[7:] in model_dict}\n",
    "            assert len(overlap_dict) == 312\n",
    "        elif not num_groups and not weight_std:\n",
    "            pretrained_dict = model_zoo.load_url(model_urls['resnet101'])\n",
    "            overlap_dict = {k: v for k, v in pretrained_dict.items() if k in model_dict}\n",
    "        else:\n",
    "            raise ValueError('Currently only support BN or GN+WS')\n",
    "        model_dict.update(overlap_dict)\n",
    "        model.load_state_dict(model_dict)\n",
    "    return model\n",
    "\n",
    "\n",
    "def resnet152(pretrained=False, **kwargs):\n",
    "    \"\"\"Constructs a ResNet-152 model.\n",
    "\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    \"\"\"\n",
    "    model = ResNet(Bottleneck, [3, 8, 36, 3], **kwargs)\n",
    "    if pretrained:\n",
    "        model.load_state_dict(model_zoo.load_url(model_urls['resnet152']))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "715f0da0-bc49-4fac-a1f1-554581042683",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "# Build Conv_layer\n",
    "class conv_block(nn.Module):\n",
    "    def __init__(self, in_c, out_c):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_c, out_c, kernel_size=3, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(out_c)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(out_c, out_c, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(out_c)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x = self.conv1(inputs)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "# Build Encoder section\n",
    "class encoder_block(nn.Module):\n",
    "    def __init__(self, in_c, out_c):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv = conv_block(in_c, out_c)\n",
    "        self.pool = nn.MaxPool2d((2, 2))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        x = self.conv(inputs)\n",
    "        p = self.pool(x)\n",
    "\n",
    "        return x, p\n",
    "\n",
    "\n",
    "# Build Decoder section\n",
    "class decoder_block(nn.Module):\n",
    "    def __init__(self, in_c, out_c):\n",
    "        super().__init__()\n",
    "\n",
    "        self.up = nn.ConvTranspose2d(in_c, out_c, kernel_size=2, stride=2, padding=0)\n",
    "        self.conv = conv_block(out_c + out_c, out_c)\n",
    "\n",
    "    def forward(self, inputs, skip):\n",
    "        x = self.up(inputs)\n",
    "        x = torch.cat([x, skip], axis=1)\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Build Unet architecture\n",
    "\n",
    "class build_unet2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # Encoder\n",
    "        self.e1 = encoder_block(3, 64)\n",
    "        self.e2 = encoder_block(64, 128)\n",
    "        self.e3 = encoder_block(128, 256)\n",
    "        self.e4 = encoder_block(256, 512)\n",
    "\n",
    "        # Bottleneck\n",
    "        self.b = conv_block(512, 1024)\n",
    "\n",
    "        # Decoder\n",
    "        self.d1 = decoder_block(1024, 512)\n",
    "        self.d2 = decoder_block(512, 256)\n",
    "        self.d3 = decoder_block(256, 128)\n",
    "        self.d4 = decoder_block(128, 64)\n",
    "\n",
    "        # Classifier\n",
    "        self.outputs = nn.Conv2d(64, 7, kernel_size=1, padding=0)\n",
    "\n",
    "    def func_with_svd(self, L: torch.Tensor, rank: int = 50):\n",
    "        reshaped_aa = L.view(L.size(0), L.size(1), -1)\n",
    "\n",
    "        u, s, v = torch.svd(reshaped_aa)\n",
    "\n",
    "        u_truncated = u[:, :, :rank]\n",
    "        s_truncated = s[:, :rank]\n",
    "        v_truncated = v[:, :, :rank]\n",
    "        reconstructed_aa = torch.matmul(torch.matmul(u_truncated, torch.diag_embed(s_truncated)),\n",
    "                                        v_truncated.transpose(1, 2))\n",
    "        reconstructed_aa  =reconstructed_aa.view(L.shape)\n",
    "\n",
    "        return reconstructed_aa\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        # Encoder\n",
    "        s1, p1 = self.e1(inputs)\n",
    "        s2, p2 = self.e2(p1)\n",
    "        s3, p3 = self.e3(p2)\n",
    "        s4, p4 = self.e4(p3)\n",
    "\n",
    "        # Bottleneck\n",
    "        b = self.b(p4)\n",
    "\n",
    "        # Decoder\n",
    "        d1 = self.d1(b, s4)\n",
    "        d2 = self.d2(d1, s3)\n",
    "        d3 = self.d3(d2, s2)\n",
    "        d4 = self.d4(d3, s1)\n",
    "        out = self.func_with_svd(d4)\n",
    "        d4  = out+d4\n",
    "\n",
    "        outputs = self.outputs(d4)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aaf888c-ba51-4aa4-9d83-6198e808d281",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cdbd4db-c4b2-44a5-bf47-1c6c9af6bde9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00665e8-c5e4-46f5-b08c-610094dd501b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
