{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0309beba-1104-4fd8-8d31-2279dd8c9ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run dataset.ipynb\n",
    "%run models.ipynb\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from operator import add\n",
    "from PIL import Image\n",
    "import segmentation_models_pytorch as smp\n",
    "import os \n",
    "\n",
    "import re\n",
    "import torch.optim as optim\n",
    "                    \n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import accuracy_score, f1_score, jaccard_score, precision_score, recall_score\n",
    "import import_ipynb\n",
    "import json\n",
    "from pyfiles.efficientunet import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ac9eac-3fb4-4c9b-b1d8-f9cb51159ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load the JSON file\n",
    "with open('dict_indices.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "train_indices = data['train_indices']\n",
    "val_indices = data['val_indices']\n",
    "\n",
    "with open('domainb_indices.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "domainb_indices = data['train']\n",
    "\n",
    "\n",
    "train_path = os.path.join(os.getcwd(),\"train\")\n",
    "mask_path = os.path.join(os.getcwd(),\"train_gt\")\n",
    "train_x = os.listdir('train')\n",
    "train_x.sort(key=extract_numerical_part)\n",
    "train_y = os.listdir('train_gt')\n",
    "train_y.sort(key=extract_numerical_part)\n",
    "\n",
    "val_path = os.path.join(os.getcwd(),\"val\")\n",
    "val_gt = os.path.join(os.getcwd(),\"val_gt\")\n",
    "val_x = os.listdir('val')\n",
    "val_x.sort(key=extract_numerical_part)\n",
    "val_y = os.listdir('val_gt')\n",
    "val_y.sort(key=extract_numerical_part)\n",
    "\n",
    "testB = os.path.join(os.getcwd(),\"imgs\")\n",
    "test_gtB = os.path.join(os.getcwd(),\"Gts\")\n",
    "path_soft_gtB  =  os.path.join(os.getcwd(),\"soft_gtB\")\n",
    "\n",
    "testB_images = os.listdir(testB)\n",
    "testB_images.sort(key=extract_numerical_part)\n",
    "testB_masks = os.listdir(test_gtB)\n",
    "testB_masks.sort(key=extract_numerical_part)\n",
    "\n",
    "\n",
    "\n",
    "# vss = dess400(train_path,mask_path,train_indices,train_transform)\n",
    "# vall = dess400(val_path,val_gt,val_indices,valid_transform)\n",
    "# dbb = dess400(testB,test_gtB,domainb_indices,train_transform)\n",
    "\n",
    "vs= Dess2(train_path,mask_path,train_x ,train_y , train_transform)\n",
    "\n",
    "val= Dess2(val_path , val_gt, val_x,val_y , valid_transform)\n",
    "domainb = hotencoded(testB , test_gtB , testB_images    , testB_masks , num_classes=7,transform=valid_transform)\n",
    "# domainb_soft = hot400(testB , path_soft_gtB, domainb_indices, num_classes=7,transform=train_transform)\n",
    "domainb_small = hot400(testB , test_gtB,domainb_indices,num_classes=7,transform=valid_transform)\n",
    "ds = hot400(train_path , mask_path,train_indices,num_classes=7,transform=train_transform)\n",
    "ds_val = hot400(val_path , val_gt , val_indices,num_classes=7,transform=valid_transform)\n",
    "# ds = hotencoded(train_path,mask_path , train_x,train_y , num_classes=7,transform=train_transform)\n",
    "# ds_val = hotencoded(val_path,val_gt,val_x,val_y,num_classes=7,transform=valid_transform)\n",
    "dbtrain,dbtest = splitset(testB_masks,0.8)\n",
    "dbtrain_l,dbtrain_ul = splitset(dbtrain,0.25)\n",
    "domainb_train_l = hot400(testB , test_gtB,dbtrain_l,num_classes=7,transform=train_transform)\n",
    "domainb_train_ul = hot400(testB , test_gtB,dbtrain_ul,num_classes=7,transform=train_transform)\n",
    "domainb_test = hot400(testB,test_gtB , dbtest,num_classes=7,transform=valid_transform)\n",
    "db_whole = hot400(testB,test_gtB,testB_masks,num_classes=7,transform=valid_transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa70459a-8e13-4c96-8d2b-72bbb25ec521",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define the label_colors\n",
    "label_colors = [\n",
    "    [0, 0, 0],       # Background (black)\n",
    "    [255, 0, 0],     # Class 1 (red)\n",
    "    [0, 255, 0],     # Class 2 (green)\n",
    "    [0, 0, 255],     # Class 3 (blue)\n",
    "    [255, 255, 0],   # Class 4 (yellow)\n",
    "    [255, 0, 255],   #Class 5 (magenta)\n",
    "    [0, 255, 255]    # Class 6 (cyan)\n",
    "]\n",
    "\n",
    "# Set the directory where the folders are located\n",
    "dir = '/home/khan/Desktop/ammar/DataAugustFull/OAI-MRI-DESS/save_masks/rawpredictions'\n",
    "\n",
    "# Get the list of folders\n",
    "ll = ['Gts', '83.605', '75.41', '72.638']\n",
    "\n",
    "# Get the list of image files starting from index 150\n",
    "image_files = [f'{i+1}.png' for i in range(3150, 3300)]\n",
    "\n",
    "# Set the image size for each subplot\n",
    "image_size = (800, 800)\n",
    "\n",
    "# Create the figure and axes\n",
    "fig, axes = plt.subplots(len(image_files), len(ll), figsize=(16, len(image_files) * 4), gridspec_kw={'wspace': 0.05, 'hspace': 0.05})\n",
    "\n",
    "# Iterate over the image files\n",
    "for i, image_file in enumerate(image_files):\n",
    "    # Iterate over the folders\n",
    "    for j, folder in enumerate(ll):\n",
    "        folder_path = os.path.join(dir, folder)\n",
    "        image_path = os.path.join(folder_path, image_file)\n",
    "        \n",
    "        # Load the image\n",
    "        mask = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "        # Create the color mask\n",
    "        color_mask = np.zeros((*mask.shape, 3), dtype=np.uint8)\n",
    "        for label in range(7):\n",
    "            color_mask[mask == label] = label_colors[label]\n",
    "        \n",
    "        # Resize the color mask to the desired size\n",
    "        color_mask = cv2.resize(color_mask, image_size)\n",
    "        \n",
    "        # Plot the color mask\n",
    "        axes[i, j].imshow(color_mask)\n",
    "        axes[i, j].set_title(f'{folder}: {image_file}', fontsize=8)\n",
    "        axes[i, j].text(0, -0.2, f'Filename: {image_file}', transform=axes[i, j].transAxes, fontsize=10)\n",
    "        axes[i, j].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27005d4-3357-4778-acc5-2f3930b933ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd8895fc-9086-430f-bf28-5fb0d6da6f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#show predictions for saved model masks \n",
    "# label_colors = [\n",
    "#     [0, 0, 0],       # Background (black)\n",
    "#     [0, 0, 0],     # Class 1 (red)\n",
    "#     [0, 255, 0],     # Class 2 (green)\n",
    "#     [0, 0, 255],     # Class 3 (blue)\n",
    "#     [255, 255, 0],   # Class 4 (yellow)\n",
    "#     [255, 0, 255],   # Class 5 (magenta)\n",
    "#     [0, 255, 255]    # Class 6 (cyan)\n",
    "# ]\n",
    "\n",
    "label_colors = [\n",
    "    [0, 0, 0],       # Background (black)\n",
    "    [0, 0, 0],     # Class 1 (red)\n",
    "    [0, 0, 0],     # Class 2 (green)\n",
    "    [0, 0, 255],     # Class 3 (blue)\n",
    "    [0,0, 0],   # Class 4 (yellow)\n",
    "    [255, 0, 255],   # Class 5 (magenta)\n",
    "    [0, 0, 0]    # Class 6 (cyan)\n",
    "]\n",
    "\n",
    "\n",
    "# Set the directory where the folders are located\n",
    "dir = '/home/khan/Desktop/ammar/DataAugustFull/OAI-MRI-DESS/save_masks/rawpredictions'\n",
    "\n",
    "# Get the list of folders\n",
    "ll = ['Gts', '83.605', '75.41', '72.638']\n",
    "\n",
    "# Define the list of image file names to show\n",
    "image_file_names = ['3270.png',  '3201.png' ]\n",
    "\n",
    "# Set the image size for each subplot\n",
    "image_size = (800, 800)\n",
    "\n",
    "# Create the figure and axes\n",
    "fig, axes = plt.subplots(len(image_file_names), len(ll), figsize=(16, len(image_file_names) * 4), gridspec_kw={'wspace': 0.05, 'hspace': 0.05})\n",
    "\n",
    "# Iterate over the image file names\n",
    "for i, image_file in enumerate(image_file_names):\n",
    "    # Iterate over the folders\n",
    "    for j, folder in enumerate(ll):\n",
    "        folder_path = os.path.join(dir, folder)\n",
    "        image_path = os.path.join(folder_path, image_file)\n",
    "        \n",
    "        # Load the image\n",
    "        mask = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE) \n",
    "        \n",
    "        # Create the color mask\n",
    "        color_mask = np.zeros((*mask.shape, 3), dtype=np.uint8)\n",
    "        for label in range(7):\n",
    "            color_mask[mask == label] = label_colors[label]\n",
    "        \n",
    "        # Resize the color mask to the desired size\n",
    "        color_mask = cv2.resize(color_mask, image_size)\n",
    "        \n",
    "        # Plot the color mask\n",
    "        axes[i, j].imshow(color_mask)\n",
    "        axes[i, j].set_title(f'{folder}: {image_file}', fontsize=8)\n",
    "        axes[i, j].text(0, -0.2, f'Filename: {image_file}', transform=axes[i, j].transAxes, fontsize=10)\n",
    "        axes[i, j].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.show()\n",
    "# Save the collage as an image file\n",
    "collage_filename = '3_5_combo.png'\n",
    "plt.savefig(collage_filename, dpi=300, bbox_inches='tight')\n",
    "print(f'Collage saved as {collage_filename}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de26f94b-7ab7-43b1-8ac8-9116e741ba1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the directory where the folders are located\n",
    "dir = '/home/khan/Desktop/ammar/DataAugustFull/OAI-MRI-DESS/save_masks/rawpredictions'\n",
    "\n",
    "# Get the list of folders\n",
    "ll = ['Gts', '83.605', '75.41', '72.638']\n",
    "\n",
    "# Define the list of image file names to save\n",
    "image_file_names = ['3241.png', '3248.png', '3204.png', '3213.png', '3251.png', '3246.png', '3270.png','3201.png']\n",
    "\n",
    "# Create the 'shortlisted' directory if it doesn't exist\n",
    "shortlisted_dir = 'shortlisted2'\n",
    "if not os.path.exists(shortlisted_dir):\n",
    "    os.makedirs(shortlisted_dir)\n",
    "\n",
    "# Iterate over the folders\n",
    "for folder in ll:\n",
    "    folder_path = os.path.join(dir, folder)\n",
    "    \n",
    "    # Iterate over the image file names\n",
    "    for image_file in image_file_names:\n",
    "        image_path = os.path.join(folder_path, image_file)\n",
    "        \n",
    "        # Load the original image\n",
    "        original_image = cv2.imread(image_path)\n",
    "        \n",
    "        # Create the new file name with the folder name and image name\n",
    "        new_filename = f\"{folder}_{image_file}\"\n",
    "        new_file_path = os.path.join(shortlisted_dir, new_filename)\n",
    "        \n",
    "        # Save the original image to the 'shortlisted' directory\n",
    "        cv2.imwrite(new_file_path, original_image)\n",
    "\n",
    "print(\"Original images saved in the 'shortlisted' directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63795821-f027-4d19-8093-1713732f8e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = cv2.imread(\"/home/khan/Desktop/ammar/DataAugustFull/OAI-MRI-DESS/save_masks/rawpredictions/53.66/2500.png\",cv2.IMREAD_GRAYSCALE)\n",
    "# plt.imshow('/home/khan/Desktop/ammar/DataAugustFull/OAI-MRI-DESS/save_masks/rawpredictions/53.66/1.png')\n",
    "\n",
    "\n",
    "dir = os.listdir('/home/khan/Desktop/ammar/DataAugustFull/OAI-MRI-DESS/save_masks/rawpredictions')\n",
    "ll=['Gts','83.605' , '75.41' , '62.36']\n",
    "\n",
    "\n",
    "color_mask = np.zeros((*mask.shape, 3), dtype=np.uint8)\n",
    "for label in range(7):  # Iterate over labels 0 to 6\n",
    "    color_mask[ == label] = label_colors[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b087e1cf-3716-40a2-b1b4-11b92910f4a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(imgs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66153d68-8715-4adf-9e9b-7676302fa211",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(color_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3939e46-e7b5-4a53-999a-10ab55e1b1b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd950b98-e329-4f80-952d-27cfaa176c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#display only groundtruth\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# # Define the label colors\n",
    "label_colors = [\n",
    "    [0, 0, 0],       # Background (black)\n",
    "    [255, 0, 0],     # Class 1 (red)\n",
    "    [0, 255, 0],     # Class 2 (green)\n",
    "    [0, 0, 255],     # Class 3 (blue)\n",
    "    [255, 255, 0],   # Class 4 (yellow)\n",
    "    [255, 0, 255],   #Class 5 (magenta)\n",
    "    [0, 255, 255]    # Class 6 (cyan)\n",
    "]\n",
    "\n",
    "# Create a color mask for the entire dataset\n",
    "count = 0\n",
    "for i in range(len(domainb)):\n",
    "    count = count+1\n",
    "    # if count==150:\n",
    "    #     break\n",
    "    image, _,mask, filename = domainb_test[i]\n",
    "    if int(filename.split('.')[0]) in shorts:\n",
    "        # Plot the input image, transformed image, transformed mask, and color mask\n",
    "        fig, axes = plt.subplots(1, 2, figsize=(16, 4))\n",
    "    \n",
    "        \n",
    "    \n",
    "        axes[0].imshow(image.permute(1,2,0))\n",
    "        axes[0].set_title('Transformed Image')\n",
    "        axes[0].axis('off')\n",
    "    \n",
    "        # Create a color mask by mapping the label values to colors\n",
    "        color_mask = np.zeros((*mask.shape, 3), dtype=np.uint8)\n",
    "        for label in range(7):  # Iterate over labels 0 to 6\n",
    "            color_mask[mask == label] = label_colors[label]\n",
    "    \n",
    "        axes[1].imshow(color_mask)\n",
    "        axes[1].set_title('Color Mask')\n",
    "        axes[1].axis('off')\n",
    "    \n",
    "        axes[1].text(0, -0.2, f'Filename: {filename}', transform=axes[1].transAxes, fontsize=12)\n",
    "    \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dafc255-ee02-444e-ae1b-d778cf47093b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyfiles.efficientunet import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e00f09-fa29-4fc4-a7be-875ec160a8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##to display and save one single image prediction\n",
    "# # import matplotlib.pyplot as plt\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# # Define the label colors (you can change the variable name to something else)\n",
    "# class_colors = [\n",
    "#         [255, 0, 0],     # Class 1 (red)\n",
    "#         [0, 255, 0],     # Class 2 (green)\n",
    "#         [0, 0, 255],     # Class 3 (blue)\n",
    "#         [255, 255, 0],   # Class 4 (yellow)\n",
    "#         [255, 0, 255],   # Class 5 (magenta)\n",
    "#         [0, 255, 255]    # Class 6 (cyan)\n",
    "#     ]\n",
    "# num_classes=7\n",
    "# # Iterate through each image in the dataset\n",
    "\n",
    "    \n",
    "# student_model.eval()       \n",
    "# with torch.no_grad():\n",
    "#     output = student_model(imgss.float().unsqueeze(0))\n",
    "# pred = torch.argmax(output, dim=1).squeeze(0)\n",
    "# pred = pred.to(\"cpu\").numpy()\n",
    "\n",
    "# #f1 score calculation \n",
    "# f1_scores = np.zeros(num_classes)\n",
    "# for class_label in range(num_classes):  # F1 score and loss for the current class\n",
    "#     pred_class = (pred == class_label)\n",
    "#     real_class = (mk == class_label)\n",
    "    \n",
    "#     true_positives = np.sum(np.logical_and(pred_class, real_class).numpy())\n",
    "#     false_positives = np.sum(np.logical_and(pred_class, ~real_class).numpy())\n",
    "#     false_negatives = np.sum(np.logical_and(~pred_class, real_class).numpy())\n",
    "    \n",
    "#     precision = true_positives / (true_positives + false_positives)\n",
    "#     recall = true_positives / (true_positives + false_negatives)\n",
    "    \n",
    "#     f1_scores[class_label] = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "# original_image = imgss.permute(1, 2, 0).numpy()\n",
    "# segmentation_mask = mk.numpy()\n",
    "# pred_mask = pred\n",
    "\n",
    "\n",
    "# # Create a copy of the original image for visualization\n",
    "# mapped_image = original_image.copy()\n",
    "# pred_img = original_image.copy()\n",
    "\n",
    "# # Apply color or overlay to each segmented region based on labels\n",
    "# for label in range(1, np.max(segmentation_mask) + 1):\n",
    "#     if label -1< len(class_colors):  # Check if a color is defined for the label\n",
    "#         region_pixels = np.where(segmentation_mask == label)\n",
    "#         mapped_image[region_pixels] = class_colors[label - 1]\n",
    "         \n",
    "# for label in range(1, np.max(pred_img) + 1):\n",
    "#     if label-1 < len(class_colors):  # Check if a color is defined for the label\n",
    "#         region_pixels = np.where(pred_mask == label)\n",
    "#         pred_img[region_pixels] = class_colors[label - 1]\n",
    "    \n",
    "# # Create subplots for original image, ground truth mask, and predicted mask\n",
    "# fig, axs = plt.subplots(1, 3, figsize=(12, 4))\n",
    "\n",
    "# # Plot the original image\n",
    "# axs[0].imshow(original_image)\n",
    "# axs[0].set_title(\"Original Image\")\n",
    "\n",
    "# # Plot the ground truth mask with mapped color labels\n",
    "# axs[1].imshow(mapped_image)\n",
    "# axs[1].set_title(\"Ground Truth Mask\")\n",
    "\n",
    "# # Plot the predicted mask mapped onto the original image\n",
    "# axs[2].imshow(pred_img)\n",
    "# axs[2].set_title(\"Predicted Mask\")\n",
    "\n",
    "# # Add the caption with the name variable\n",
    "# axs[2].text(0.5, -0.1, m, transform=axs[2].transAxes, ha='center')\n",
    "\n",
    "# # Remove axis labels\n",
    "# for ax in axs:\n",
    "#     ax.axis(\"off\")\n",
    "\n",
    "# # # Save the figure to a local directory\n",
    "# # # pred_img_bgr = pred_img[..., ::-1]\n",
    "\n",
    "# # save_dir = '/home/khan/Desktop/ammar/DataAugustFull/OAI-MRI-DESS/partitions/3126'\n",
    "# # os.makedirs(save_dir, exist_ok=True)\n",
    "# # img_name = os.path.join(save_dir,model_name)\n",
    "# # plt.imsave(img_name,pred_img)\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8cebf60-b0ce-4ddc-ba73-acd54a20b027",
   "metadata": {},
   "outputs": [],
   "source": [
    "['efb4-full.png','studentSW_efb4_257520.png','student_efb4_257520.png','resnet34.png'] #api models \n",
    "['studentsvdSW3_efb4_ponit05.png','studentsvdSW_efb4_257520.png','studentsvdSW2_efb4_257520.png','newefb4svd-full.pth',\n",
    "'studentTsvd_efb4_257520.png', '2_efb4_ponit05.png', 'studentsvdSW3_efb4_356520.pth'] #sutombackbones \n",
    "[fivepercent ]\n",
    "#percentages\n",
    "[28 , 81.33,0.5, 25 ] #api models \n",
    "\n",
    "[52.89, 84.23 , 85.07,44.72, 82.50,77.64]\n",
    "[65.78] #five percent \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1573ef27-1473-4040-ae3c-324b7f7ed2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "device=\"cuda\"\n",
    "\n",
    "model = smp.Unet(\n",
    "    encoder_name=\"resnet34\",        # choose encoder, e.g. mobilenet_v2 or efficientnet-b7\n",
    "    encoder_weights=\"imagenet\",     # use `imagenet` pre-trained weights for encoder initialization\n",
    "    in_channels=3,                  # model input channels (1 for gray-scale images, 3 for RGB, etc.)\n",
    "    classes=7,                      # model output channels (number of classes in your dataset)\n",
    ")\n",
    "old_teacher_model = smp.Unet(\n",
    "    encoder_name=\"efficientnet-b4\",        # choose encoder, e.g. mobilenet_v2 or efficientnet-b7\n",
    "    encoder_weights=\"imagenet\",     # use `imagenet` pre-trained weights for encoder initialization\n",
    "    in_channels=3,                  # model input channels (1 for gray-scale images, 3 for RGB, etc.)\n",
    "    classes=7,                      # model output channels (number of classes in your dataset)\n",
    ")\n",
    "student_model = get_efficientunet_b4(out_channels=7, concat_input=True, pretrained=True)\n",
    "# old_teacher_model.load_state_dict(torch.load(\"2_efb4_ponit05.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106eae65-495a-41d0-a9cc-53efb4a58f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('resnet34.pth'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a56965-37f2-42b6-bc9e-4d88c7e15598",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = CategoricalFocalLoss(gamma=2.0, alpha=None, reduction='mean')\n",
    "num_classes=7\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adba1796-6a6f-4a3a-86b7-d278443bdae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "student_model=model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e4e9527-ab45-4386-86b2-815b3815871c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#0,2,4,\n",
    "\n",
    "student_model.load_state_dict(torch.load('studentsvdSW2_efb4_257520.pth'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b7288f-d1fb-4fcd-a571-369ce2993ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "student_model = student_model.to(device)\n",
    "l,t,tt= validlossf2(student_model,domainb_test,loss_fn,num_classes)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340c4ab9-cf1b-44a8-8b2f-0f3534991a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "l,t,tt,df = validlossJ(student_model, domainb_test, loss_fn , num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55926e3-d463-4b96-bf21-23c621e2ce61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ae9e2a-a383-4384-9bad-7c18e8fb1524",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(cv2.imread('/home/khan/Desktop/ammar/DataAugustFull/OAI-MRI-DESS/save_masks/rawpredictions/62.36/200.png',cv2.IMREAD_GRAYSCALE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "587226ad-aa3f-4577-832d-3529e2eaee3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Define the label colors (you can change the variable name to something else)\n",
    "class_colors = [\n",
    "        [255, 0, 0],     # Class 1 (red)\n",
    "        [0, 255, 0],     # Class 2 (green)\n",
    "        [0, 0, 255],     # Class 3 (blue)\n",
    "        [255, 255, 0],   # Class 4 (yellow)\n",
    "        [255, 0, 255],   # Class 5 (magenta)\n",
    "        [0, 255, 255]    # Class 6 (cyan)\n",
    "    ]\n",
    "\n",
    "# Iterate through each image in the dataset\n",
    "student_model.eval()\n",
    "for image, _, mask, name in domainb:\n",
    "    image=image.to(device)\n",
    "    mask = mask.to(device)\n",
    "    \n",
    "    # if int(name.split('.')[0]) in pics:\n",
    "    \n",
    "    student_model.to(device)    \n",
    "    with torch.no_grad():\n",
    "       \n",
    "        result = student_model(image.float().unsqueeze(0))\n",
    "        predictions = torch.argmax(result, dim=1)\n",
    "        pred_labels = predictions.squeeze().cpu().numpy()\n",
    "    \n",
    "    original_image = image.permute(1, 2, 0).cpu().numpy()\n",
    "    segmentation_mask = mask.cpu().numpy()\n",
    "    pred_mask = pred_labels\n",
    "\n",
    "        \n",
    "    # Create a copy of the original image for visualization\n",
    "    mapped_image = original_image.copy()\n",
    "    pred_img = original_image.copy()\n",
    "\n",
    "    for label in range(1, np.max(segmentation_mask) + 1):\n",
    "        if label -1< len(class_colors):  # Check if a color is defined for the label\n",
    "            region_pixels = np.where(segmentation_mask == label)\n",
    "            mapped_image[region_pixels] = class_colors[label - 1]\n",
    "     \n",
    "    for label in range(1, np.max(pred_img) + 1):\n",
    "        if label-1 < len(class_colors):  # Check if a color is defined for the label\n",
    "            region_pixels = np.where(pred_mask == label)\n",
    "            pred_img[region_pixels] = class_colors[label - 1]\n",
    "\n",
    "    # Create subplots for original image, ground truth mask, and predicted mask\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(12, 4))\n",
    "\n",
    "    # Plot the original image\n",
    "    axs[0].imshow(original_image)\n",
    "    axs[0].set_title(\"Original Image\")\n",
    "\n",
    "    # Plot the ground truth mask with mapped color labels\n",
    "    axs[1].imshow(mapped_image)\n",
    "    axs[1].set_title(\"Ground Truth Mask\")\n",
    "\n",
    "    # Plot the predicted mask mapped onto the original image\n",
    "    axs[2].imshow(pred_img)\n",
    "    axs[2].set_title(\"Predicted Mask\")\n",
    "\n",
    "    # Add the caption with the name variable\n",
    "    axs[2].text(0.5, -0.1, name, transform=axs[2].transAxes, ha='center')\n",
    "\n",
    "    # Remove axis labels\n",
    "    for ax in axs:\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "    # Save the figure to a local directory\n",
    "    # pred_img_bgr = pred_img[..., ::-1]\n",
    "\n",
    "#     save_dir = '/home/khan/Desktop/ammar/DataAugustFull/OAI-MRI-DESS/save_masks/domainb_rawpredictions/62.36'\n",
    "#     os.makedirs(save_dir, exist_ok=True)\n",
    "#     img_name = os.path.join(save_dir,name)\n",
    "#     # plt.imsave(img_name,pred_labels)\n",
    "#     cv2.imwrite(img_name,pred_mask.astype(np.uint8))\n",
    "# print(\"ALL SAVED\")\n",
    "    # # Show the subplots\n",
    "    plt.tight_layout()\n",
    "plt.show()\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f525db-303e-4e04-b830-09cffefdd792",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validlossJ(model, ds, loss_fn, num_classes):\n",
    "    jaccard_list = []\n",
    "    loss_list = []\n",
    "    \n",
    "    model.eval()\n",
    "    for img, mask, orig, _ in ds:\n",
    "        img = img.to(device)\n",
    "        mask = mask.to(device)\n",
    "        with torch.no_grad():\n",
    "            output = model(img.float().unsqueeze(0))\n",
    "        loss = loss_fn(output, mask.float().unsqueeze(0))\n",
    "        pred = torch.argmax(output, dim=1).squeeze(0)\n",
    "        pred = pred.to(\"cpu\")\n",
    "        \n",
    "        jaccard_scores = np.zeros(num_classes)\n",
    "        \n",
    "        for class_label in range(num_classes):  # Jaccard Index and loss for the current class\n",
    "            pred_class = (pred == class_label)\n",
    "            real_class = (orig == class_label)\n",
    "            \n",
    "            intersection = np.sum(np.logical_and(pred_class, real_class).numpy())\n",
    "            union = np.sum(np.logical_or(pred_class, real_class).numpy())\n",
    "            \n",
    "            jaccard_scores[class_label] = intersection / union\n",
    "        \n",
    "        jaccard_list.append(np.round(list(jaccard_scores), 5))\n",
    "        loss_list.append(loss.item())\n",
    "      \n",
    "    average_loss = np.average(loss_list)\n",
    "    jaccard_df = pd.DataFrame(jaccard_list)\n",
    "    jaccard_avg = jaccard_df[jaccard_df != 0].mean()\n",
    "    average_jaccard = np.round(np.average(jaccard_avg), 5)\n",
    "\n",
    "    return np.round(average_loss, 7), np.round(average_jaccard, 5), np.round(jaccard_avg, 5), jaccard_df\n",
    "\n",
    "def validlossf3(model, ds, loss_fn, num_classes):\n",
    "    f1_list = []\n",
    "    loss_list = []\n",
    "    \n",
    "    model.eval()\n",
    "    for img, mask, orig, _ in ds:\n",
    "        img = img.to(device)\n",
    "        mask = mask.to(device)\n",
    "        with torch.no_grad():\n",
    "            output = model(img.float().unsqueeze(0))\n",
    "        loss = loss_fn(output, mask.float().unsqueeze(0))\n",
    "        pred = torch.argmax(output, dim=1).squeeze(0)\n",
    "        pred = pred.to(\"cpu\")\n",
    "        \n",
    "        f1_scores = np.zeros(num_classes)\n",
    "        \n",
    "        for class_label in range(num_classes):  # F1 score and loss for the current class\n",
    "            pred_class = (pred == class_label)\n",
    "            real_class = (orig == class_label)\n",
    "            \n",
    "            true_positives = np.sum(np.logical_and(pred_class, real_class).numpy())\n",
    "            false_positives = np.sum(np.logical_and(pred_class, ~real_class).numpy())\n",
    "            false_negatives = np.sum(np.logical_and(~pred_class, real_class).numpy())\n",
    "            \n",
    "            precision = true_positives / (true_positives + false_positives)\n",
    "            recall = true_positives / (true_positives + false_negatives)\n",
    "            \n",
    "            f1_scores[class_label] = 2 * (precision * recall) / (precision + recall)\n",
    "        \n",
    "        f1_list.append(np.round(list(f1_scores),5))\n",
    "        loss_list.append(loss.item())\n",
    "      \n",
    "    average_loss = np.average(loss_list)\n",
    "    f1df = pd.DataFrame(f1_list)\n",
    "    f1avg = f1df[f1df != 0].mean()\n",
    "    average_f1 = np.round(np.average(f1avg),5)\n",
    "\n",
    "    return np.round(average_loss,7), np.round(average_f1,5), np.round(f1avg,5),f1df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1912ac1-6fbd-426d-b6ee-cf7958fd936f",
   "metadata": {},
   "outputs": [],
   "source": [
    "domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d2750c-411e-4503-8832-57f1065b70f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fdict={} \n",
    "f1_scores=[]\n",
    "for md in modelss:\n",
    "    if md in [\"efb4-full.pth\",'studentSW_efb4_257520.pth','student_efb4_257520.pth','resnet34.pth']:\n",
    "        pass\n",
    "    else:\n",
    "        student_model.load_state_dict(torch.load(md,map_location = torch.device(device)))\n",
    "    \n",
    "        with torch.no_grad():\n",
    "            output = student_model(imgss.float().unsqueeze(0))\n",
    "        pred = torch.argmax(output, dim=1).squeeze(0)\n",
    "        pred = pred.to(\"cpu\")\n",
    "                \n",
    "        f1_scores = np.zeros(num_classes)\n",
    "        for class_label in range(num_classes):  # F1 score and loss for the current class\n",
    "            pred_class = (pred == class_label)\n",
    "            real_class = (mk == class_label)\n",
    "            \n",
    "            true_positives = np.sum(np.logical_and(pred_class, real_class).numpy())\n",
    "            false_positives = np.sum(np.logical_and(pred_class, ~real_class).numpy())\n",
    "            false_negatives = np.sum(np.logical_and(~pred_class, real_class).numpy())\n",
    "            \n",
    "            precision = true_positives / (true_positives + false_positives)\n",
    "            recall = true_positives / (true_positives + false_negatives)\n",
    "            \n",
    "            f1_scores[class_label] = 2 * (precision * recall) / (precision + recall)\n",
    "        fdict[md] = f1_scores[-1]\n",
    "                \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059c9213-ffaf-4d33-b74d-bc1f2f343a29",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1374c115-8b63-4d5f-9c16-a22d6b8ce8b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pics = [2663, 2666,2745,2746,2755,2756,2773,2774,2786,2797,2810\n",
    ",2811]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353a25a6-9838-4d5f-93d9-eea6b40e725b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69bec189-ee0f-43f3-906a-0f4e55cd68fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "ll = os.listdir(os.path.join(dir,\"sourcefree\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b7405c-6745-42c4-b47f-a96ab309d148",
   "metadata": {},
   "outputs": [],
   "source": [
    "ll.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e1e1e2f-6c42-4832-b3fb-619fd1712be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "i,t,tt=validlossf1(student_model,domainb,loss_fn,num_classes=7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde9feea-7565-48e9-9793-c42f214c2263",
   "metadata": {},
   "outputs": [],
   "source": [
    "name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de7454d-6033-427c-9ac0-290424620a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = '/home/khan/Desktop/ammar/DataAugustFull/OAI-MRI-DESS/save_masks'\n",
    "os.listdir(dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1feacc8-f700-4137-8fc0-a2e5e4df83c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(os.path.join(dir,'studentSW_efb4_257520.pth_dbtest_80.88'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a8407c-a611-4068-b1c7-68b4e08bf042",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b95374-1704-4641-8477-83c708ef1949",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565faf76-4c01-493f-8f58-8466de24fa77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the directory path where the images are located\n",
    "directory_path = dir\n",
    "# Define the list of folder names containing the images\n",
    "folder_names = ['images','masks','resnet34.pth','2_efb4_ponit05.pth']\n",
    " \n",
    "\n",
    "# Sort the folder names based on accuracy from highest to lowest\n",
    "folder_names.sort(key=lambda x: float(x.split('_dbtest_')[1].split('.png')[0]) if '_dbtest_' in x else -1, reverse=True)\n",
    "\n",
    "# Define the list of image names\n",
    "image_names = [str(pic) + '.png' for pic in [2663, 2745, 2755, 2773, 2786, 2811]]\n",
    "\n",
    "# Calculate the number of images per row\n",
    "images_per_row = len(folder_names)\n",
    "\n",
    "# Calculate the number of rows\n",
    "num_rows = len(image_names)\n",
    "\n",
    "# Set the figure size based on the number of images\n",
    "fig_width = 4 * images_per_row\n",
    "fig_height = 4 * num_rows\n",
    "fig, axs = plt.subplots(num_rows, images_per_row, figsize=(fig_width, fig_height))\n",
    "\n",
    "# Iterate over the image names and plot the corresponding images from each folder\n",
    "for i, image_name in enumerate(image_names):\n",
    "    for j, folder_name in enumerate(folder_names):\n",
    "        # Get the path of the image in the current folder\n",
    "        image_path = os.path.join(directory_path, folder_name, image_name)\n",
    "\n",
    "        # Load and plot the image\n",
    "        image = plt.imread(image_path)\n",
    "        axs[i, j].imshow(image)\n",
    "        axs[i, j].axis('off')\n",
    "\n",
    "        # Add titles to the folder names for the first row\n",
    "        if i == 0:\n",
    "            axs[0, j].set_title(folder_name, fontsize=10)\n",
    "\n",
    "# Remove spacing between subplots\n",
    "plt.subplots_adjust(wspace=0, hspace=0)\n",
    "\n",
    "# Show the grid of images\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0652e9ad-7ad1-46ac-860e-7b1ad2cc30d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Define the directory path where the images are located\n",
    "directory_path = dir\n",
    "\n",
    "\n",
    "\n",
    "# Define the list of folder names containing the images\n",
    "# Define the list of folder names containing the images in the desired order\n",
    "folder_names = ['images','masks',\n",
    " 'proposed',\n",
    " 'cps',\n",
    " 'fldkd',\n",
    " 'mt',\n",
    "'uda1','uda2', 'sourcefree',\n",
    " ]\n",
    "\n",
    "# Define the list of image names in the desired order\n",
    "image_names = ['2663.png', '2786.png', '2745.png', '2811.png', '2755.png', '2773.png']\n",
    "\n",
    "# Calculate the number of images per row\n",
    "images_per_row = len(folder_names)\n",
    "\n",
    "# Calculate the number of rows\n",
    "num_rows = len(image_names)\n",
    "\n",
    "# Set the figure size based on the number of images\n",
    "fig_width = 4 * images_per_row\n",
    "fig_height = 4 * num_rows\n",
    "fig, axs = plt.subplots(num_rows, images_per_row, figsize=(fig_width, fig_height))\n",
    "\n",
    "# Iterate over the image names and plot the corresponding images from each folder\n",
    "for i, image_name in enumerate(image_names):\n",
    "    for j, folder_name in enumerate(folder_names):\n",
    "        # Get the path of the image in the current folder\n",
    "        image_path = os.path.join(directory_path, folder_name, image_name)\n",
    "\n",
    "        # Load and plot the image\n",
    "        image = plt.imread(image_path)\n",
    "        axs[i, j].imshow(image)\n",
    "        axs[i, j].axis('off')\n",
    "\n",
    "# Remove spacing between subplots\n",
    "fig.subplots_adjust(wspace=0, hspace=0)\n",
    "\n",
    "# Remove any extra space around the figure\n",
    "fig.tight_layout()\n",
    "\n",
    "# Show the grid of images\n",
    "plt.show()\n",
    "plt.savefig('/path/to/save/grid_image.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52526aaf-788e-4195-b330-ab0d837f8b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "student_model.load_state_dict(torch.load(\"partitions/five_percent.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477ef489-1241-497e-8fa1-4b0274edd375",
   "metadata": {},
   "outputs": [],
   "source": [
    "student_model = student_model.to(device)\n",
    "i,t,tt,df=validlossf3(student_model,domainb_test,loss_fn,num_classes=7)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f4629f-f9d3-4dab-8e02-631051385824",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(domainb_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fef44dc-a392-4ec4-ad8d-23dd4c5a9001",
   "metadata": {},
   "outputs": [],
   "source": [
    "#___________________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f8677b-d6e9-47ea-97be-137ec116f7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=torch.load(\"/home/khan/Desktop/ammar/EfficientUnet-PyTorch-master/ftmap\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6cc5a1-b07f-4ad4-a22a-4f207ab08d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we iterate over each channel of the feature map and plot it as a separate heatmap using the imshow function.\n",
    "#The colorbar function is called to add a colorbar to each heatmap. This way, you can visualize each channel individually.\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming you have a feature map with dimensions (1792, 12, 12)\n",
    "feature_map = a.to(\"cpu\").detach().numpy()\n",
    "\n",
    "# Normalize the feature map values between 0 and 1\n",
    "normalized_map = (feature_map - feature_map.min()) / (feature_map.max() - feature_map.min())\n",
    "\n",
    "# Iterate over the channels and plot them as heatmaps\n",
    "for channel in range(feature_map.shape[0]):\n",
    "    plt.imshow(normalized_map[channel], cmap='hot')\n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51cbfbc1-4288-4242-b04d-c5d0cf4f0c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize individual channels of the feature maps as grayscale images and display them side by side\n",
    "# Normalize the feature map values between 0 and 1\n",
    "normalized_map = (feature_map - feature_map.min()) / (feature_map.max() - feature_map.min())\n",
    "\n",
    "# Select random channels to visualize\n",
    "num_channels = 5  # Number of channels to visualize\n",
    "selected_channels = np.random.choice(range(feature_map.shape[0]), num_channels, replace=False)\n",
    "\n",
    "# Plot selected channels as grayscale images\n",
    "fig, axes = plt.subplots(1, num_channels, figsize=(15, 3))\n",
    "\n",
    "for i, channel in enumerate(selected_channels):\n",
    "    axes[i].imshow(normalized_map[channel], cmap='gray')\n",
    "    axes[i].set_title(f'Channel {channel}')\n",
    "    axes[i].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5daa8d5f-dcbe-4244-ad65-26e051ba50f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# Assuming you have a feature map with dimensions (1792, 12, 12)\n",
    "\n",
    "\n",
    "# Stack the channels together to create a 3D volume\n",
    "stacked_volume = np.stack(normalized_map, axis=-1)\n",
    "\n",
    "# Create a 3D plot\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# Set the x, y, z dimensions of the plot\n",
    "x, y, z = np.meshgrid(range(stacked_volume.shape[0]), range(stacked_volume.shape[1]), range(stacked_volume.shape[2]))\n",
    "\n",
    "# Plot the 3D volume\n",
    "ax.scatter(x, y, z, c=stacked_volume.reshape(-1), cmap='hot')\n",
    "\n",
    "# Set labels and title\n",
    "ax.set_xlabel('Channel')\n",
    "ax.set_ylabel('X')\n",
    "ax.set_zlabel('Y')\n",
    "ax.set_title('3D Visualization of Feature Maps')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e05a83e-a087-4ccc-86a7-86269ca0d381",
   "metadata": {},
   "outputs": [],
   "source": [
    "b=torch.load(\"before\")\n",
    "af=torch.load(\"after\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d44d431-408e-456d-b23e-d7aa5110672e",
   "metadata": {},
   "outputs": [],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ce07ca-74b6-4cf1-924b-da6a24669c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(a[100].detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b714a8-a964-420f-acab-30a8c006cfeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "b=b.squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a9bf183-d25c-4013-b252-e92d052a9b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "b= torch.mean(b,dim=0)\n",
    "# The result is a single channel with dimensions (width, height)\n",
    "print(b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf7e138-e84f-44f9-baf7-47d1d15c4407",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "af= torch.mean(af,dim=0)\n",
    "# The result is a single channel with dimensions (width, height)\n",
    "print(af.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df962543-8cf2-4997-ad49-d81feaaddd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.imshow(af)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c98f02-486d-46de-acaf-a53f2908850e",
   "metadata": {},
   "outputs": [],
   "source": [
    "b=b.squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6b2cc5-fd25-4a6c-8bfa-8cde22304042",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the feature map to have 10 feature maps per row\n",
    "# Assuming you have a feature map of size torch.Size([1792, 12, 12])\n",
    "feature_map = b\n",
    "# Reshape the feature map to have 10 feature maps per row\n",
    "# Reshape the feature map to have 10 feature maps per row\n",
    "num_feature_maps = feature_map.shape[0]\n",
    "num_rows = (num_feature_maps + 9) // 10\n",
    "feature_map_grid = feature_map.view(num_rows, 10, feature_map.shape[1], feature_map.shape[2])\n",
    "\n",
    "# Create the visualization grid\n",
    "grid = utils.make_grid(feature_map_grid.flatten(0, 1), nrow=10, padding=1)\n",
    "\n",
    "# Display the grid\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.imshow(grid.permute(1, 2, 0), cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a187ea92-d175-4e8d-920f-80ba3e374228",
   "metadata": {},
   "outputs": [],
   "source": [
    "b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9302e147-ffcf-4938-bc84-6c1353fb9216",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(b[0],cmap='grey')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466cb016-9dbb-4703-bfce-fb680958d767",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
